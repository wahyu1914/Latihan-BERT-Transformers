{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "_RR8nfALt1O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Db9s2ZfFoXZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "metadata": {
        "id": "oKH8PYYFq0iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"mohler_dataset_edited.csv\")\n",
        "\n",
        "# Define input features and target\n",
        "X = df[[\"question\", \"desired_answer\", \"student_answer\"]]\n",
        "y = df[\"score_avg\"]\n",
        "\n",
        "# Split into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Combine X and y for train and test sets\n",
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "test_data = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "# Optional: print the shape to confirm\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "BVXRiQpUo-5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "train_data.to_csv(\"train.csv\", index=False)\n",
        "test_data.to_csv(\"test.csv\", index=False)"
      ],
      "metadata": {
        "id": "T2MyFZ6RqJxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def preprocess(row):\n",
        "    return tokenizer(\n",
        "        f\"question: {row['question']} reference: {row['desired_answer']} answer: {row['student_answer']}\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "gQC6zmFksU2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MohlerDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        tokens = self.tokenizer(\n",
        "            f\"question: {row['question']} reference: {row['desired_answer']} answer: {row['student_answer']}\",\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': tokens['input_ids'].squeeze(),\n",
        "            'attention_mask': tokens['attention_mask'].squeeze(),\n",
        "            'label': torch.tensor(row['score_avg'], dtype=torch.float)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "PzSH5PBRsU53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "import torch.nn as nn\n",
        "\n",
        "class BERTRegressor(nn.Module):\n",
        "    def __init__(self, model_name=\"bert-base-uncased\"):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        return self.regressor(pooled_output).squeeze(-1)"
      ],
      "metadata": {
        "id": "IzP-bF8CsU91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "pvjG_AajsVBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSVs\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Dataset & DataLoader\n",
        "train_dataset = MohlerDataset(train_df, tokenizer)\n",
        "test_dataset = MohlerDataset(test_df, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8)\n"
      ],
      "metadata": {
        "id": "1QN7V_1LsVEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = BERTRegressor().to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "num_epochs = 30\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "1xyueVkRsVIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    print(f\"\\nEpoch {epoch+1} - Avg Train Loss: {avg_train_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "QGSwwA6DsVMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "preds = []\n",
        "targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        preds.extend(outputs.cpu().numpy())\n",
        "        targets.extend(labels.cpu().numpy())\n",
        "\n",
        "mse = mean_squared_error(targets, preds)\n",
        "print(f\"Test MSE: {mse:.4f}\")\n"
      ],
      "metadata": {
        "id": "Vl-JZfvGsVPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"bert_asas_mohler.pt\")"
      ],
      "metadata": {
        "id": "ZTLnRwz9sVz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Explain the concept of recursion in programming.\"\n",
        "desired_answer = \"Recursion is a programming technique where a function calls itself to solve smaller instances of a problem.\"\n",
        "student_answer = \"I like turtles because they have nice shells and swim fast.\"\n"
      ],
      "metadata": {
        "id": "c92oGyomsV18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "    question + \" [SEP] \" + desired_answer + \" [SEP] \" + student_answer,\n",
        "    return_tensors=\"pt\",\n",
        "    truncation=True,\n",
        "    padding=True\n",
        ").to(device)\n"
      ],
      "metadata": {
        "id": "OOA8rTZJsV_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():  # disable gradient tracking\n",
        "    output = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "\n",
        "predicted_score = output.item()\n",
        "print(f\"Predicted Score: {predicted_score:.2f}\")"
      ],
      "metadata": {
        "id": "8NeHvSnEsWBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bt6aS_FPsWFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ke3bPrEsWHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gQ_Cu3lcsWJn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}